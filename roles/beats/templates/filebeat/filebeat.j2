###################### Filebeat Configuration Example #########################
# ============================== Filebeat inputs ===============================

filebeat.inputs:

- type: filestream

  # Unique ID among all inputs, an ID is required.
  id: my-filestream-id

  # Change to true to enable this input configuration.
  enabled: true

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /var/log/*.log
    #- c:\programdata\elasticsearch\logs\*

  #exclude_lines: ['^DBG']

  #include_lines: ['^ERR', '^WARN']

  #prospector.scanner.exclude_files: ['.gz$']

  #fields:
  #  level: debug
  #  review: 1

# ============================== Filebeat modules ==============================

filebeat.config.modules:
  # Glob pattern for configuration loading
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  reload.enabled: true

  # Period on which files under path should be checked for changes
  #reload.period: 10s

# ======================= Elasticsearch template setting =======================

setup.template.settings:
  index.number_of_shards: {{ filebeat_number_of_shards }}
  index.number_of_replicas: {{ filebeat_number_of_replicas }}
  #index.codec: best_compression
  #_source.enabled: false


# ================================== General ===================================
#name:

# The tags of the shipper are included in their own field with each
# transaction published.
#tags: ["service-X", "web-tier"]

# Optional fields that you can specify to add additional information to the
# output.
#fields:
#  env: staging

{% if setup_kibana_dashboards == "yes" %}
# =================================== Kibana ===================================
setup.kibana:
{% if elk_auth_ssl == "yes" %}
  host:
  {% for host in groups['kibana'] %}
  - {{ hostvars[host]['ansible_host'] }}:{{ es_port }}
  {% endfor %}
  
  ssl:
    enabled: true
    certificate_authorities: "{{ filebeat_certs_dir }}/{{ elasticsearch_ca_pem }}"
  {% else %}
  host:
  {% for host in groups['kibana'] %}
  - {{ hostvars[host]['ansible_host'] }}:{{ es_port }}
  {% endfor %}
{% endif %}
{% endif %}

# ---------------------------- Elasticsearch Output ----------------------------

{% if output_log_elastic == "yes" %}
output.elasticsearch:
  # Array of hosts to connect to.
{% if elk_auth_ssl == "yes" %}
  hosts: 
  {% for host in groups['elastic_master'] %}
  - {{ hostvars[host]['ansible_host'] }}:{{ es_port }}
  {% endfor %}
  protocol: "https"
  username: "{{ es_username }}"
  password: "{{ es_password }}"
  ssl:
     enabled: true
     certificate_authorities: "{{ filebeat_certs_dir }}/{{ elasticsearch_ca_pem }}"
{% else %}
  hosts: 
  {% for host in groups['elastic_master'] %}
  - {{ hostvars[host]['ansible_host'] }}:{{ es_port }}
  {% endfor %}
{% endif %}
{% endif %}
     
# ------------------------------ Logstash Output -------------------------------
{% if output_log_logstash == "yes" %}
output.logstash:
  # The Logstash hosts
  hosts: 
  {% for host in groups['logstash'] %}
  - {{ hostvars[host]['ansible_host'] }}:{{ lo_port }}
  {% endfor %}
{% endif %}

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"

# ================================= Processors =================================
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~
setup.ilm.overwrite: true
